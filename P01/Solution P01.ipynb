{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Congruent</th>\n",
       "      <th>Incongruent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.079</td>\n",
       "      <td>19.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.791</td>\n",
       "      <td>18.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.564</td>\n",
       "      <td>21.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.630</td>\n",
       "      <td>15.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.669</td>\n",
       "      <td>22.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.238</td>\n",
       "      <td>20.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.692</td>\n",
       "      <td>24.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.987</td>\n",
       "      <td>17.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.401</td>\n",
       "      <td>20.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.480</td>\n",
       "      <td>26.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.328</td>\n",
       "      <td>24.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.298</td>\n",
       "      <td>18.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.073</td>\n",
       "      <td>17.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.929</td>\n",
       "      <td>20.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.200</td>\n",
       "      <td>35.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.130</td>\n",
       "      <td>22.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.495</td>\n",
       "      <td>25.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.639</td>\n",
       "      <td>20.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.344</td>\n",
       "      <td>17.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.369</td>\n",
       "      <td>34.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12.944</td>\n",
       "      <td>23.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14.233</td>\n",
       "      <td>17.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19.710</td>\n",
       "      <td>22.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16.004</td>\n",
       "      <td>21.157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Congruent  Incongruent\n",
       "0      12.079       19.278\n",
       "1      16.791       18.741\n",
       "2       9.564       21.214\n",
       "3       8.630       15.687\n",
       "4      14.669       22.803\n",
       "5      12.238       20.878\n",
       "6      14.692       24.572\n",
       "7       8.987       17.394\n",
       "8       9.401       20.762\n",
       "9      14.480       26.282\n",
       "10     22.328       24.524\n",
       "11     15.298       18.644\n",
       "12     15.073       17.510\n",
       "13     16.929       20.330\n",
       "14     18.200       35.255\n",
       "15     12.130       22.158\n",
       "16     18.495       25.139\n",
       "17     10.639       20.429\n",
       "18     11.344       17.425\n",
       "19     12.369       34.288\n",
       "20     12.944       23.894\n",
       "21     14.233       17.960\n",
       "22     19.710       22.058\n",
       "23     16.004       21.157"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "data = pd.read_table('UdacityP01Sheet1.csv', sep= \",\")\n",
    "congruent= data.Congruent\n",
    "incongruent= data.Incongruent\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is our independent variable? What is our dependent variable?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Independent Variable: Congruent and Incongruent nature of the test. \n",
    "Depenent variable: Time taken by each individual to correctly complete the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What is an appropriate set of hypotheses for this task? What kind of statistical test do you expect to perform? Justify your choices."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The appropriate hypothesis is as following: \n",
    "Let U1 and U2 be the mean time for congruent test and incongruent test. \n",
    "H0: Time it takes to name the ink colors in equally-sized lists in both Congrunet and Incongruent are equal or has no difference.  (H0: u1= u2)\n",
    "H1: Time it takes to name the ink colors in equally-sized lists in Congrunet and Incongruent are not equal(H1: u1!=u2)\n",
    "\n",
    "I would expect to perform t-test as the sample size is small than 30,and we have no any information about the population, its SD or mean. \n",
    "\n",
    "Since the data is dependent we use paired test. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Report some descriptive statistics regarding this dataset. Include at least one measure of central tendency and at least one measure of variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean time of congruent challange is : 14.051125\n",
      "median time of congruent challange is : 14.3565\n",
      "standard deviation of congruent challange is : 3.55935795765\n",
      "variance of congruent challange is : 12.6690290707\n",
      "--------------------------\n",
      "mean time of Incongruent challange is : 22.0159166667\n",
      "median time of Incongruent challange is : 21.0175\n",
      "standard deviation of Incongruent challange is : 4.79705712247\n",
      "variance of Incongruent challange is : 23.0117570362\n",
      "--------------------------\n",
      "             Congruent  Incongruent\n",
      "Congruent    12.669029     6.007123\n",
      "Incongruent   6.007123    23.011757\n",
      "--------------------------\n",
      "Conclusion:Since the mean and median value of the two data set are nearly equal, we can conclude the data is quit uniform \n"
     ]
    }
   ],
   "source": [
    "#mean of congruent and Incongruent \n",
    "mean = data.mean()\n",
    "mean_cong= mean[0]\n",
    "mean_incong= mean[1]\n",
    "\n",
    "#median of congruent and Incongruent \n",
    "median=data.median()\n",
    "median_cong=median[0]\n",
    "median_incong= median[1]\n",
    "\n",
    "#standard deviation of congruent and Incongruent \n",
    "std= data.std()\n",
    "std_cong=std[0]\n",
    "std_incong=std[1]\n",
    "\n",
    "#variance deviation of congruent and Incongruent \n",
    "variance=data.var()\n",
    "variance_cong=variance[0]\n",
    "variance_incong=variance[1]\n",
    "\n",
    "#covariance deviation of congruent and Incongruent \n",
    "cov=data.cov()\n",
    "\n",
    "print (\"mean time of congruent challange is :\", mean_cong)\n",
    "print (\"median time of congruent challange is :\", median_cong)\n",
    "print (\"standard deviation of congruent challange is :\",std_cong)\n",
    "print (\"variance of congruent challange is :\",variance_cong)\n",
    "\n",
    "print(\"--------------------------\")\n",
    "print (\"mean time of Incongruent challange is :\", mean_incong)\n",
    "print (\"median time of Incongruent challange is :\",median_incong)\n",
    "print (\"standard deviation of Incongruent challange is :\",std_incong)\n",
    "print (\"variance of Incongruent challange is :\",variance_incong)\n",
    "print(\"--------------------------\")\n",
    "print (cov)\n",
    "print(\"--------------------------\")\n",
    "print(\"Conclusion:Since the mean and median value of the two data set are nearly equal, we can conclude the data is quit uniform \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Provide one or two visualizations that show the distribution of the sample data. Write one or two sentences noting what you observe about the plot or plots."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Visualization of barchart is attached with this folder. \n",
    "From the visualization it is clear that it takes less time to read the congruent dataset whereas long time to read the incongruent dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Now, perform the statistical test and report your results. What is your confidence level and your critical statistic value? Do you reject the null hypothesis or fail to reject it? Come to a conclusion in terms of the experiment task. Did the results match up with your expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t test value= 8.020706944109957\n"
     ]
    }
   ],
   "source": [
    "# Let us asume the u1 and u2 be the populaion mean of congruent test and incongruent test resp. \n",
    "\n",
    "#H0: Time it takes to name the color of ink in equally-sized lists in both Congrunet and Incongruent are equal (H0: u1= u2)\n",
    "#H1: Time it takes to name the color of ink in equally-sized lists in Congrunet and Incongruent are not equal(H1: u1!=u2)\n",
    "# Our level of sugnificance is 0.01\n",
    "\n",
    "\n",
    "data[\"dA\"] = data['Incongruent']-data[\"Congruent\"]\n",
    "\n",
    "mean = data[\"dA\"].mean()\n",
    "sd = data[\"dA\"].std()\n",
    "SE= sd/math.sqrt(24)\n",
    "t= mean/ SE \n",
    "\n",
    "#print(\"Degree_of_freedom=\", Degree_of_freedom)\n",
    "\n",
    "print (\"t test value=\",t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabulated T value or critical value  at 0.01 level of significance and 23 degree of freedom for two tailed test is 2.807"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus modulus of t calculated test value (8.020)>> critical value(2.87) at 1% level of significance. \n",
    "Thus we reject the null hypothesis and accept the alternate hypothesis. That is :time it takes to name the color of ink in equally-sized lists in Congrunet and Incongruent are not equal. \n",
    "\n",
    "Yes, the experiment matched my expectation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
